{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading MNIST dataset...\n",
      "MNIST dataset loaded.\n",
      "Creating dataset subsets...\n",
      "Dataset subsets created.\n",
      "\n",
      "--- Training 10 models for Class 1 (Digits [0, 1, 2, 3]) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 1 (Digits [0, 1, 2, 3]):  10%|█         | 1/10 [00:07<01:03,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 1/10:\n",
      "    Training Acc (Class 1 (Digits [0, 1, 2, 3])): 99.30%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 98.80%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 51.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 1 (Digits [0, 1, 2, 3]):  20%|██        | 2/10 [00:14<00:57,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 2/10:\n",
      "    Training Acc (Class 1 (Digits [0, 1, 2, 3])): 99.23%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 98.92%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 51.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 1 (Digits [0, 1, 2, 3]):  30%|███       | 3/10 [00:21<00:48,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 3/10:\n",
      "    Training Acc (Class 1 (Digits [0, 1, 2, 3])): 99.05%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 98.77%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 51.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 1 (Digits [0, 1, 2, 3]):  40%|████      | 4/10 [00:27<00:41,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 4/10:\n",
      "    Training Acc (Class 1 (Digits [0, 1, 2, 3])): 99.20%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 98.97%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 51.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 1 (Digits [0, 1, 2, 3]):  50%|█████     | 5/10 [00:34<00:34,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 5/10:\n",
      "    Training Acc (Class 1 (Digits [0, 1, 2, 3])): 99.30%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 99.06%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 51.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 1 (Digits [0, 1, 2, 3]):  60%|██████    | 6/10 [00:42<00:28,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 6/10:\n",
      "    Training Acc (Class 1 (Digits [0, 1, 2, 3])): 99.21%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 99.09%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 51.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 1 (Digits [0, 1, 2, 3]):  70%|███████   | 7/10 [00:49<00:21,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 7/10:\n",
      "    Training Acc (Class 1 (Digits [0, 1, 2, 3])): 99.20%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 98.94%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 51.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 1 (Digits [0, 1, 2, 3]):  80%|████████  | 8/10 [00:56<00:14,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 8/10:\n",
      "    Training Acc (Class 1 (Digits [0, 1, 2, 3])): 99.23%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 99.11%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 51.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 1 (Digits [0, 1, 2, 3]):  90%|█████████ | 9/10 [01:04<00:07,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 9/10:\n",
      "    Training Acc (Class 1 (Digits [0, 1, 2, 3])): 99.00%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 98.99%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 51.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 1 (Digits [0, 1, 2, 3]): 100%|██████████| 10/10 [01:11<00:00,  7.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 10/10:\n",
      "    Training Acc (Class 1 (Digits [0, 1, 2, 3])): 99.02%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 98.97%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 51.30%\n",
      "\n",
      "--- Results for models trained on Class 1 (Digits [0, 1, 2, 3]) ---\n",
      "Average Training Accuracy (Class 1 (Digits [0, 1, 2, 3])): 99.17% (Std Dev: 0.10)\n",
      "Average Testing Accuracy (Class 1 Test (Digits [0, 1, 2, 3])): 98.96% (Std Dev: 0.11)\n",
      "Average Testing Accuracy (Class 2 Test (Digits [2, 3, 4, 5])): 51.34% (Std Dev: 0.13)\n",
      "--------------------------------------------------\n",
      "Saved Class 1 model weights to ./trained_models/class1_models_weights.pt\n",
      "\n",
      "--- Training 10 models for Class 2 (Digits [2, 3, 4, 5]) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 2 (Digits [2, 3, 4, 5]):  10%|█         | 1/10 [00:06<01:00,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 1/10:\n",
      "    Training Acc (Class 2 (Digits [2, 3, 4, 5])): 98.36%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 97.88%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 47.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 2 (Digits [2, 3, 4, 5]):  20%|██        | 2/10 [00:13<00:55,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 2/10:\n",
      "    Training Acc (Class 2 (Digits [2, 3, 4, 5])): 98.80%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 98.24%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 48.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 2 (Digits [2, 3, 4, 5]):  30%|███       | 3/10 [00:21<00:49,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 3/10:\n",
      "    Training Acc (Class 2 (Digits [2, 3, 4, 5])): 98.71%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 98.19%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 48.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 2 (Digits [2, 3, 4, 5]):  40%|████      | 4/10 [00:28<00:42,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 4/10:\n",
      "    Training Acc (Class 2 (Digits [2, 3, 4, 5])): 98.48%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 98.31%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 48.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 2 (Digits [2, 3, 4, 5]):  50%|█████     | 5/10 [00:34<00:34,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 5/10:\n",
      "    Training Acc (Class 2 (Digits [2, 3, 4, 5])): 98.93%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 98.57%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 48.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 2 (Digits [2, 3, 4, 5]):  60%|██████    | 6/10 [00:41<00:27,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 6/10:\n",
      "    Training Acc (Class 2 (Digits [2, 3, 4, 5])): 98.61%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 98.16%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 47.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 2 (Digits [2, 3, 4, 5]):  70%|███████   | 7/10 [00:48<00:20,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 7/10:\n",
      "    Training Acc (Class 2 (Digits [2, 3, 4, 5])): 98.72%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 98.34%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 47.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 2 (Digits [2, 3, 4, 5]):  80%|████████  | 8/10 [00:55<00:13,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 8/10:\n",
      "    Training Acc (Class 2 (Digits [2, 3, 4, 5])): 98.59%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 98.47%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 48.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 2 (Digits [2, 3, 4, 5]):  90%|█████████ | 9/10 [01:02<00:06,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 9/10:\n",
      "    Training Acc (Class 2 (Digits [2, 3, 4, 5])): 98.45%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 97.96%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 47.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models for Class 2 (Digits [2, 3, 4, 5]): 100%|██████████| 10/10 [01:09<00:00,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model 10/10:\n",
      "    Training Acc (Class 2 (Digits [2, 3, 4, 5])): 98.74%\n",
      "    Testing Acc (Class 2 Test (Digits [2, 3, 4, 5])): 98.16%\n",
      "    Testing Acc (Class 1 Test (Digits [0, 1, 2, 3])): 48.11%\n",
      "\n",
      "--- Results for models trained on Class 2 (Digits [2, 3, 4, 5]) ---\n",
      "Average Training Accuracy (Class 2 (Digits [2, 3, 4, 5])): 98.64% (Std Dev: 0.17)\n",
      "Average Testing Accuracy (Class 2 Test (Digits [2, 3, 4, 5])): 98.23% (Std Dev: 0.20)\n",
      "Average Testing Accuracy (Class 1 Test (Digits [0, 1, 2, 3])): 48.06% (Std Dev: 0.23)\n",
      "--------------------------------------------------\n",
      "Saved Class 2 model weights to ./trained_models/class2_models_weights.pt\n",
      "\n",
      "Experiment complete!\n",
      "Class 1 model weights stored in 'class1_model_weights' (list of 10 state_dicts).\n",
      "Class 2 model weights stored in 'class2_model_weights' (list of 10 state_dicts).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### data generation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os # Import the os module for path operations\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_MODELS = 10\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 3  # A small number of epochs for quick training of many models\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Define the classes for each subset\n",
    "CLASS1_LABELS = [0, 1, 2, 3]\n",
    "CLASS2_LABELS = [2, 3, 4, 5]\n",
    "\n",
    "# Set device to GPU if available, otherwise CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Set random seeds for reproducibility (for dataset splitting, model init, etc.)\n",
    "# Note: Training 1000 models means there will still be inherent randomness\n",
    "# due to different initializations and data shuffling.\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "elif torch.backends.mps.is_available(): # For Apple Silicon\n",
    "    # MPS does not have a manual_seed_all equivalent for all operations.\n",
    "    # Deterministic behavior for MPS is generally handled by setting seeds for CPU/GPU.\n",
    "    # For full reproducibility, you might need to disable MPS for some operations,\n",
    "    # or accept minor variations.\n",
    "    pass\n",
    "\n",
    "# --- Data Loading and Preprocessing ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # MNIST mean and std\n",
    "])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "print(\"Loading MNIST dataset...\")\n",
    "full_train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "full_test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "print(\"MNIST dataset loaded.\")\n",
    "\n",
    "# --- Dataset Subset Creation Function ---\n",
    "def create_subset(dataset, labels_to_include):\n",
    "    \"\"\"\n",
    "    Filters a dataset to include only samples with specified labels.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for i, (_, label) in enumerate(dataset):\n",
    "        if label in labels_to_include:\n",
    "            indices.append(i)\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "# Create the specific subsets\n",
    "print(\"Creating dataset subsets...\")\n",
    "class1_train_dataset = create_subset(full_train_dataset, CLASS1_LABELS)\n",
    "class1_test_dataset = create_subset(full_test_dataset, CLASS1_LABELS) # Test set for Class 1 labels\n",
    "\n",
    "class2_train_dataset = create_subset(full_train_dataset, CLASS2_LABELS)\n",
    "class2_test_dataset = create_subset(full_test_dataset, CLASS2_LABELS) # Test set for Class 2 labels\n",
    "print(\"Dataset subsets created.\")\n",
    "\n",
    "# --- Neural Network Definition (3 LAYERS) ---\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Input layer: 28*28 = 784 pixels\n",
    "        # Hidden layer 1: 64 neurons\n",
    "        # Hidden layer 2: 32 neurons\n",
    "        # Output layer: 10 neurons (for digits 0-9, even if only a subset is trained)\n",
    "        self.fc1 = nn.Linear(28 * 28, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(32, 10) # Output 10 classes for MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28) # Flatten the 28x28 image\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# --- Training Function ---\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    \"\"\"Trains a single neural network model.\"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# --- Evaluation Function ---\n",
    "def evaluate_model(model, data_loader, description=\"\"):\n",
    "    \"\"\"Evaluates a single neural network model and returns accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    if len(data_loader.dataset) == 0:\n",
    "        return float('nan')\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# --- Main Experiment Logic ---\n",
    "def run_experiment(train_dataset, self_test_dataset, cross_test_dataset,\n",
    "                   train_description, self_test_description, cross_test_description):\n",
    "    \"\"\"\n",
    "    Runs the training and evaluation for a given set of datasets.\n",
    "    Returns a list of trained model state_dicts.\n",
    "    \"\"\"\n",
    "    train_accuracies = []\n",
    "    self_test_accuracies = []\n",
    "    cross_test_accuracies = []\n",
    "    trained_model_weights = [] # List to store model weights\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    self_test_loader = DataLoader(self_test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    cross_test_loader = DataLoader(cross_test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    print(f\"\\n--- Training {NUM_MODELS} models for {train_description} ---\")\n",
    "    for i in tqdm(range(NUM_MODELS), desc=f\"Training models for {train_description}\"):\n",
    "        model = SimpleNN().to(DEVICE)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        # Train the model\n",
    "        train_model(model, train_loader, criterion, optimizer, NUM_EPOCHS)\n",
    "\n",
    "        # Save the model's state_dict (weights)\n",
    "        trained_model_weights.append(model.state_dict())\n",
    "\n",
    "        # Evaluate accuracies\n",
    "        train_acc = evaluate_model(model, train_loader, f\"{train_description} Training\")\n",
    "        self_test_acc = evaluate_model(model, self_test_loader, f\"{self_test_description} Testing\")\n",
    "        cross_test_acc = evaluate_model(model, cross_test_loader, f\"{cross_test_description} Testing\")\n",
    "\n",
    "        train_accuracies.append(train_acc)\n",
    "        self_test_accuracies.append(self_test_acc)\n",
    "        cross_test_accuracies.append(cross_test_acc)\n",
    "\n",
    "        # Print accuracy after each run\n",
    "        print(f\"  Model {i+1}/{NUM_MODELS}:\")\n",
    "        print(f\"    Training Acc ({train_description}): {train_acc:.2f}%\")\n",
    "        print(f\"    Testing Acc ({self_test_description}): {self_test_acc:.2f}%\")\n",
    "        print(f\"    Testing Acc ({cross_test_description}): {cross_test_acc:.2f}%\")\n",
    "\n",
    "    # Calculate and print average results\n",
    "    avg_train_acc = np.mean(train_accuracies)\n",
    "    std_train_acc = np.std(train_accuracies)\n",
    "    avg_self_test_acc = np.mean(self_test_accuracies)\n",
    "    std_self_test_acc = np.std(self_test_accuracies)\n",
    "    avg_cross_test_acc = np.mean(cross_test_accuracies)\n",
    "    std_cross_test_acc = np.std(cross_test_accuracies)\n",
    "\n",
    "    print(f\"\\n--- Results for models trained on {train_description} ---\")\n",
    "    print(f\"Average Training Accuracy ({train_description}): {avg_train_acc:.2f}% (Std Dev: {std_train_acc:.2f})\")\n",
    "    print(f\"Average Testing Accuracy ({self_test_description}): {avg_self_test_acc:.2f}% (Std Dev: {std_self_test_acc:.2f})\")\n",
    "    print(f\"Average Testing Accuracy ({cross_test_description}): {avg_cross_test_acc:.2f}% (Std Dev: {std_cross_test_acc:.2f})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return trained_model_weights # Return the list of weights\n",
    "\n",
    "# Define a directory to save the models\n",
    "SAVE_DIR = './trained_models'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True) # Create the directory if it doesn't exist\n",
    "\n",
    "# Run the experiment for Class 1 models\n",
    "class1_model_weights = run_experiment(class1_train_dataset, class1_test_dataset, class2_test_dataset,\n",
    "                                      f\"Class 1 (Digits {CLASS1_LABELS})\",\n",
    "                                      f\"Class 1 Test (Digits {CLASS1_LABELS})\",\n",
    "                                      f\"Class 2 Test (Digits {CLASS2_LABELS})\")\n",
    "\n",
    "# Save the weights for Class 1 models\n",
    "class1_save_path = os.path.join(SAVE_DIR, 'class1_models_weights.pt')\n",
    "torch.save(class1_model_weights, class1_save_path)\n",
    "print(f\"Saved Class 1 model weights to {class1_save_path}\")\n",
    "\n",
    "# Run the experiment for Class 2 models\n",
    "class2_model_weights = run_experiment(class2_train_dataset, class2_test_dataset, class1_test_dataset,\n",
    "                                      f\"Class 2 (Digits {CLASS2_LABELS})\",\n",
    "                                      f\"Class 2 Test (Digits {CLASS2_LABELS})\",\n",
    "                                      f\"Class 1 Test (Digits {CLASS1_LABELS})\")\n",
    "\n",
    "# Save the weights for Class 2 models\n",
    "class2_save_path = os.path.join(SAVE_DIR, 'class2_models_weights.pt')\n",
    "torch.save(class2_model_weights, class2_save_path)\n",
    "print(f\"Saved Class 2 model weights to {class2_save_path}\")\n",
    "\n",
    "print(\"\\nExperiment complete!\")\n",
    "print(f\"Class 1 model weights stored in 'class1_model_weights' (list of {len(class1_model_weights)} state_dicts).\")\n",
    "print(f\"Class 2 model weights stored in 'class2_model_weights' (list of {len(class2_model_weights)} state_dicts).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading MNIST dataset...\n",
      "MNIST dataset loaded.\n",
      "\n",
      "--- Starting Model Surgery Pipeline ---\n",
      "Loading weights from: ./trained_models/class1_models_weights.pt\n",
      "Loading weights from: ./trained_models/class2_models_weights.pt\n",
      "Loaded Model A (trained on 0,1,2,3).\n",
      "Loaded Model B (trained on 2,3,4,5).\n",
      "\n",
      "Step 2: Training a linear probe on Model B for 'digit 4 vs not-4'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting probe training data from Model B's domain: 100%|██████████| 23352/23352 [00:00<00:00, 26822.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training the probe network...\n",
      "  Probe W4 extracted. Shape: torch.Size([32])\n",
      "\n",
      "Step 3: Aligning hidden bases using Orthogonal Procrustes\n",
      "  Orthogonal Procrustes matrix R computed. Shape: torch.Size([32, 32])\n",
      "\n",
      "Step 4: Transporting the probe\n",
      "  Transported probe W_tilde_4 computed. Shape: torch.Size([32])\n",
      "\n",
      "Step 5: Locating the behaviour region in Model A's classifier layer\n",
      "  Selected rows for surgical edit (indices): [5]\n",
      "  Corresponding cosine similarities: [-0.18029682338237762]\n",
      "\n",
      "Step 6: Performing surgical edit on Model A's classifier weights\n",
      "  Surgical edit applied to 1 row(s) of Model A's fc3.weight.\n",
      "\n",
      "Step 7: Copying output weight and bias for class 4 from Model B to Model A\n",
      "  Class 4 weight and bias copied from Model B to Model A's output layer.\n",
      "Surgically modified Model A created and loaded with new weights.\n",
      "\n",
      "Step 8: Performing Sanity Tests on Surgically Modified Model A\n",
      "  Surgically Modified Model A Accuracy on original digits ([0, 1, 2, 3]): 98.92%\n",
      "  Surgically Modified Model A Accuracy on target digit (4): 0.00%\n",
      "  Surgically Modified Model A Accuracy on out-of-class digit (5): 0.00%\n",
      "\n",
      "--- Original Model A Performance (for comparison) ---\n",
      "  Original Model A Accuracy on original digits ([0, 1, 2, 3]): 98.92%\n",
      "  Original Model A Accuracy on target digit (4): 0.00%\n",
      "  Original Model A Accuracy on out-of-class digit (5): 0.00%\n",
      "\n",
      "Model surgery pipeline complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scipy.linalg import orthogonal_procrustes # For Step 3\n",
    "\n",
    "# --- Configuration ---\n",
    "SAVE_DIR = './trained_models'\n",
    "PLOTS_DIR = './surgery_plots' # Directory for new plots related to surgery\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "CLASS1_WEIGHTS_PATH = os.path.join(SAVE_DIR, 'class1_models_weights.pt')\n",
    "CLASS2_WEIGHTS_PATH = os.path.join(SAVE_DIR, 'class2_models_weights.pt')\n",
    "\n",
    "# Data loading and model training parameters (should match your experiment setup)\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS_PROBE = 5 # More epochs for probe training for better accuracy\n",
    "LEARNING_RATE_PROBE = 0.001\n",
    "\n",
    "# Define the classes for each subset\n",
    "CLASS1_LABELS = [0, 1, 2, 3] # Digits Model A was originally trained on\n",
    "CLASS2_LABELS = [2, 3, 4, 5] # Digits Model B was originally trained on\n",
    "SHARED_LABELS_FOR_ALIGNMENT = [2, 3] # Digits common to both Class 1 and Class 2 for Procrustes alignment\n",
    "TARGET_DIGIT_TO_TRANSFER = 4 # The digit whose knowledge we want to transfer from Model B to Model A\n",
    "OOC_DIGIT_TO_MONITOR = 5 # Digit that Model A should ideally remain ignorant of\n",
    "\n",
    "# Surgical parameters\n",
    "ALPHA = 0.8 # Scaling factor for the transferred probe (Step 6) - controls strength of injection\n",
    "K_ROWS_TO_PRUNE = 1 # Number of rows (output neurons) in A's classifier to modify (Step 5)\n",
    "\n",
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "elif torch.backends.mps.is_available():\n",
    "    pass\n",
    "\n",
    "# --- Data Loading and Preprocessing (MNIST) ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # MNIST mean and std\n",
    "])\n",
    "\n",
    "print(\"Loading MNIST dataset...\")\n",
    "full_train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "full_test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "print(\"MNIST dataset loaded.\")\n",
    "\n",
    "# --- Dataset Subset Creation Function ---\n",
    "def create_subset(dataset, labels_to_include):\n",
    "    \"\"\"Filters a dataset to include only samples with specified labels.\"\"\"\n",
    "    indices = []\n",
    "    for i, (_, label) in enumerate(dataset):\n",
    "        if label in labels_to_include:\n",
    "            indices.append(i)\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "# Create specific datasets for the pipeline\n",
    "# These are used for evaluation and for collecting data for the probe and alignment\n",
    "eval_set_A_labels_test_dataset = create_subset(full_test_dataset, CLASS1_LABELS) # Test set for 0,1,2,3\n",
    "target_digit_test_dataset = create_subset(full_test_dataset, [TARGET_DIGIT_TO_TRANSFER]) # Test set for digit 4\n",
    "ooc_digit_test_dataset = create_subset(full_test_dataset, [OOC_DIGIT_TO_MONITOR]) # Test set for digit 5\n",
    "\n",
    "# Dataset for probe training on Model B's knowledge.\n",
    "# It includes the target digit (4) and other digits Model B knows (2,3,5)\n",
    "# The probe will learn to distinguish 4 from (2,3,5).\n",
    "probe_train_dataset_B = create_subset(full_train_dataset, CLASS2_LABELS)\n",
    "probe_test_dataset_B = create_subset(full_test_dataset, CLASS2_LABELS)\n",
    "\n",
    "# Dataset for Orthogonal Procrustes alignment.\n",
    "# Uses digits that both Model A and Model B are familiar with.\n",
    "shared_data_for_alignment = create_subset(full_test_dataset, SHARED_LABELS_FOR_ALIGNMENT)\n",
    "\n",
    "# --- SimpleNN Model Definition (MUST MATCH YOUR TRAINING SCRIPT) ---\n",
    "# This architecture is critical for loading saved weights correctly.\n",
    "# It should be identical to the SimpleNN in 'mnist-subset-nn-experiment' Canvas.\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Input layer: 28*28 = 784 pixels\n",
    "        # Hidden layer 1: 64 neurons\n",
    "        # Hidden layer 2: 32 neurons\n",
    "        # Output layer: 10 neurons (for digits 0-9)\n",
    "        self.fc1 = nn.Linear(28 * 28, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(32, 10) # Output 10 classes for MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28) # Flatten the 28x28 image\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Method to extract hidden features from the penultimate hidden layer (Step 1)\n",
    "    # This is the output of the 'fc2' layer after ReLU.\n",
    "    def get_hidden_features(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x) # This is the penultimate hidden layer\n",
    "        x = self.relu2(x) # Apply ReLU to get the features\n",
    "        return x\n",
    "\n",
    "# --- Probe Network Definition (for Step 2) ---\n",
    "class ProbeNN(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(ProbeNN, self).__init__()\n",
    "        # A simple linear layer that takes the hidden features and outputs a single logit\n",
    "        # for binary classification (digit 4 vs. not-4).\n",
    "        self.linear = nn.Linear(feature_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def load_model_weights(path):\n",
    "    \"\"\"Loads a list of state_dicts from a .pt file.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Model weights file not found: {path}\\n\"\n",
    "                                \"Please ensure you have run the 'MNIST Subset Neural Network Experiment' Canvas \"\n",
    "                                \"to generate and save these model weights first, and that SAVE_DIR is correct.\")\n",
    "    print(f\"Loading weights from: {path}\")\n",
    "    # Use map_location='cpu' to load to CPU regardless of where they were saved, then move to DEVICE\n",
    "    # weights_only=True is recommended for security and best practice\n",
    "    return torch.load(path, map_location=DEVICE, weights_only=True)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    \"\"\"Trains a single neural network model.\"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def evaluate_model_accuracy(model, data_loader):\n",
    "    \"\"\"Evaluates a single neural network model and returns accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    if len(data_loader.dataset) == 0:\n",
    "        return float('nan') # Handle empty datasets gracefully\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def get_hidden_activations(model, data_loader):\n",
    "    \"\"\"Collects hidden layer activations for a given model and data loader.\"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    hidden_features = []\n",
    "    labels = []\n",
    "    with torch.no_grad(): # No gradients needed for feature extraction\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            # Use the specific get_hidden_features method of SimpleNN\n",
    "            hidden_feats = model.get_hidden_features(data)\n",
    "            hidden_features.append(hidden_feats.cpu()) # Move to CPU to concatenate\n",
    "            labels.append(target.cpu())\n",
    "    return torch.cat(hidden_features), torch.cat(labels)\n",
    "\n",
    "# --- Main Surgical Pipeline ---\n",
    "def run_model_surgery_pipeline():\n",
    "    print(\"\\n--- Starting Model Surgery Pipeline ---\")\n",
    "\n",
    "    # Load pre-trained Class 1 (Model A) and Class 2 (Model B) models\n",
    "    try:\n",
    "        class1_models_sd = load_model_weights(CLASS1_WEIGHTS_PATH)\n",
    "        class2_models_sd = load_model_weights(CLASS2_WEIGHTS_PATH)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Please ensure you have run the 'MNIST Subset Neural Network Experiment' Canvas to generate these models.\")\n",
    "        return\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error loading model weights: {e}\")\n",
    "        print(\"This often means the SimpleNN architecture in this script does not match the saved weights.\")\n",
    "        print(\"Please ensure the SimpleNN in 'mnist-subset-nn-experiment' Canvas is identical to this script's SimpleNN,\")\n",
    "        print(\"and then re-run 'mnist-subset-nn-experiment' to regenerate compatible weights.\")\n",
    "        return\n",
    "\n",
    "    # Pick one model from each class for the surgery\n",
    "    model_A = SimpleNN().to(DEVICE)\n",
    "    # random.choice returns a state_dict, load it into the model instance\n",
    "    model_A.load_state_dict(random.choice(class1_models_sd))\n",
    "    print(\"Loaded Model A (trained on 0,1,2,3).\")\n",
    "\n",
    "    model_B = SimpleNN().to(DEVICE)\n",
    "    model_B.load_state_dict(random.choice(class2_models_sd))\n",
    "    print(\"Loaded Model B (trained on 2,3,4,5).\")\n",
    "\n",
    "    # --- Step 2: Train a linear probe on B for “digit 4 vs not-4” ---\n",
    "    print(\"\\nStep 2: Training a linear probe on Model B for 'digit 4 vs not-4'\")\n",
    "    \n",
    "    # Prepare data for probe training:\n",
    "    # Labels for probe: 1 for TARGET_DIGIT_TO_TRANSFER (4), 0 for other digits in CLASS2_LABELS (2,3,5)\n",
    "    probe_data_B_raw = []\n",
    "    probe_labels_B_binary = []\n",
    "    \n",
    "    for img, label in tqdm(probe_train_dataset_B, desc=\"Collecting probe training data from Model B's domain\"):\n",
    "        probe_data_B_raw.append(img)\n",
    "        # Assign binary label: 1 if it's the target digit, 0 otherwise\n",
    "        probe_labels_B_binary.append(1 if label == TARGET_DIGIT_TO_TRANSFER else 0)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    probe_data_B_raw = torch.stack(probe_data_B_raw)\n",
    "    probe_labels_B_binary = torch.tensor(probe_labels_B_binary, dtype=torch.float32).unsqueeze(1) # Ensure shape (N, 1)\n",
    "\n",
    "    # Create a DataLoader for the raw image data to pass through Model B\n",
    "    probe_train_loader_raw = DataLoader(\n",
    "        torch.utils.data.TensorDataset(probe_data_B_raw, probe_labels_B_binary),\n",
    "        batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Instantiate the probe network. Feature_dim is the output size of SimpleNN's penultimate layer (fc2).\n",
    "    feature_dim = model_B.fc2.out_features # This is 32 for our current SimpleNN\n",
    "    probe_net = ProbeNN(feature_dim).to(DEVICE)\n",
    "    probe_criterion = nn.BCEWithLogitsLoss() # Use BCEWithLogitsLoss for binary classification with logits\n",
    "    probe_optimizer = optim.Adam(probe_net.parameters(), lr=LEARNING_RATE_PROBE)\n",
    "\n",
    "    # Freeze Model B's weights and collect hidden features for probe training\n",
    "    model_B.eval() # Ensure Model B is in eval mode for feature extraction, no gradients needed for Model B\n",
    "    probe_hidden_features = []\n",
    "    probe_targets = []\n",
    "    with torch.no_grad(): # No gradients needed for Model B's forward pass\n",
    "        for data, target in probe_train_loader_raw:\n",
    "            data = data.to(DEVICE)\n",
    "            hidden_feats = model_B.get_hidden_features(data) # Extract features\n",
    "            probe_hidden_features.append(hidden_feats)\n",
    "            probe_targets.append(target.to(DEVICE)) # Target is already (batch_size, 1) here\n",
    "    \n",
    "    # Create a DataLoader for the extracted hidden features to train the probe\n",
    "    probe_train_loader_features = DataLoader(\n",
    "        torch.utils.data.TensorDataset(torch.cat(probe_hidden_features), torch.cat(probe_targets)),\n",
    "        batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Train the probe network\n",
    "    print(\"  Training the probe network...\")\n",
    "    train_model(probe_net, probe_train_loader_features, probe_criterion, probe_optimizer, NUM_EPOCHS_PROBE)\n",
    "\n",
    "    # Extract W4 (the weight of the linear probe layer). It's a 1x_feature_dim tensor.\n",
    "    W4 = probe_net.linear.weight.data.clone().detach().squeeze(0) # Shape (feature_dim,)\n",
    "    print(f\"  Probe W4 extracted. Shape: {W4.shape}\")\n",
    "\n",
    "    # --- Step 3: Align B’s hidden basis to A’s hidden basis with a bridging map ---\n",
    "    print(\"\\nStep 3: Aligning hidden bases using Orthogonal Procrustes\")\n",
    "    \n",
    "    # Collect hidden vectors for shared digits (2 and 3) from the test set for alignment\n",
    "    shared_loader = DataLoader(shared_data_for_alignment, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Get hidden activations from Model A and Model B for the shared data\n",
    "    H_A_shared, _ = get_hidden_activations(model_A, shared_loader)\n",
    "    H_B_shared, _ = get_hidden_activations(model_B, shared_loader)\n",
    "\n",
    "    if H_A_shared.shape[0] == 0 or H_B_shared.shape[0] == 0:\n",
    "        print(\"  Warning: No shared data found for alignment. Skipping Procrustes. This may lead to poor transfer.\")\n",
    "        R = torch.eye(feature_dim, device=DEVICE) # Use identity matrix if no shared data\n",
    "    else:\n",
    "        # Orthogonal Procrustes: find R such that R @ H_B_shared.T approx H_A_shared.T\n",
    "        # scipy's orthogonal_procrustes expects (num_samples, num_features)\n",
    "        # It returns R_np such that B @ R_np is closest to A. So, H_B_shared @ R_np approx H_A_shared.\n",
    "        # We want R such that R @ H_B_shared.T to be H_A_shared.T, then we need to transpose inputs for orthogonal_procrustes\n",
    "        # or use it as orthogonal_procrustes(A, B) finds R such that A @ R is closest to B.\n",
    "        # So, if we want R @ H_B_shared.T to be H_A_shared.T, then we need to transpose inputs for orthogonal_procrustes\n",
    "        # or use it as orthogonal_procrustes(H_A_shared, H_B_shared) to get R such that H_A_shared @ R is closest to H_B_shared\n",
    "        # The common usage is to find R such that X @ R is closest to Y. So, we want H_B_shared @ R to be H_A_shared.\n",
    "        # Therefore, we pass (H_B_shared, H_A_shared) to orthogonal_procrustes.\n",
    "        R_np, _ = orthogonal_procrustes(H_B_shared.numpy(), H_A_shared.numpy())\n",
    "        R = torch.tensor(R_np, dtype=torch.float32, device=DEVICE)\n",
    "        print(f\"  Orthogonal Procrustes matrix R computed. Shape: {R.shape}\")\n",
    "\n",
    "    # --- Step 4: Transport the probe ---\n",
    "    print(\"\\nStep 4: Transporting the probe\")\n",
    "    # W_tilde_4 = R @ W4 (R is feature_dim x feature_dim, W4 is feature_dim)\n",
    "    # W4 needs to be a column vector for matrix multiplication, then squeeze back to 1D\n",
    "    W_tilde_4 = (R @ W4.unsqueeze(1)).squeeze(1) # R is (dim, dim), W4 is (dim,), result (dim,)\n",
    "    print(f\"  Transported probe W_tilde_4 computed. Shape: {W_tilde_4.shape}\")\n",
    "\n",
    "    # --- Step 5: Locate the behaviour region in A ---\n",
    "    print(\"\\nStep 5: Locating the behaviour region in Model A's classifier layer\")\n",
    "    # Get Model A's classifier weights (fc3.weight)\n",
    "    # This layer takes input from the second hidden layer (32 neurons) and outputs 10 logits.\n",
    "    W_clf_A = model_A.fc3.weight.data.clone().detach() # Shape (10, 32)\n",
    "    \n",
    "    # Calculate cosine similarity for each row (output neuron's weight vector) of W_clf_A with W_tilde_4\n",
    "    # Normalize W_clf_A rows (each output neuron's weight vector)\n",
    "    W_clf_A_norm = torch.nn.functional.normalize(W_clf_A, p=2, dim=1) # Normalize along the feature dimension\n",
    "    # Normalize W_tilde_4 (the transported probe)\n",
    "    W_tilde_4_norm = torch.nn.functional.normalize(W_tilde_4, p=2, dim=0) # Normalize as a vector\n",
    "\n",
    "    # Cosine similarity: (num_classes, feature_dim) @ (feature_dim, 1) -> (num_classes, 1)\n",
    "    cosine_similarities = (W_clf_A_norm @ W_tilde_4_norm.unsqueeze(1)).squeeze(1) # Result shape (10,)\n",
    "    \n",
    "    # Choose the bottom-k rows (largest negative similarity, meaning most \"opposite\" direction)\n",
    "    # Sort in ascending order (smallest values first), take the first k indices\n",
    "    sorted_indices = torch.argsort(cosine_similarities, descending=False)\n",
    "    selected_rows_indices = sorted_indices[:K_ROWS_TO_PRUNE]\n",
    "    print(f\"  Selected rows for surgical edit (indices): {selected_rows_indices.tolist()}\")\n",
    "    print(f\"  Corresponding cosine similarities: {cosine_similarities[selected_rows_indices].tolist()}\")\n",
    "\n",
    "    # --- Step 6: Surgical edit ---\n",
    "    print(\"\\nStep 6: Performing surgical edit on Model A's classifier weights\")\n",
    "    # Create a copy of model_A's state_dict to modify\n",
    "    modified_model_A_sd = model_A.state_dict()\n",
    "    \n",
    "    # Get the weight tensor for fc3.weight (the classifier layer)\n",
    "    fc3_weight_tensor = modified_model_A_sd['fc3.weight'].clone().detach()\n",
    "\n",
    "    for idx in selected_rows_indices:\n",
    "        # Apply the edit: v_i <- v_i + alpha * W_tilde_4\n",
    "        # W_tilde_4 is (feature_dim,), fc3_weight_tensor[idx] is also (feature_dim,)\n",
    "        fc3_weight_tensor[idx] = fc3_weight_tensor[idx] + ALPHA * W_tilde_4.to(fc3_weight_tensor.device)\n",
    "    \n",
    "    # Update the state dict with the modified weight tensor\n",
    "    modified_model_A_sd['fc3.weight'] = fc3_weight_tensor\n",
    "    print(f\"  Surgical edit applied to {K_ROWS_TO_PRUNE} row(s) of Model A's fc3.weight.\")\n",
    "\n",
    "    # --- Step 7: Add an output weight for class 4 ---\n",
    "    print(\"\\nStep 7: Copying output weight and bias for class 4 from Model B to Model A\")\n",
    "    # Get class 4 weights and bias from Model B's fc3 layer\n",
    "    class4_weight_B = model_B.fc3.weight.data[TARGET_DIGIT_TO_TRANSFER].clone().detach() # Shape (feature_dim,)\n",
    "    class4_bias_B = model_B.fc3.bias.data[TARGET_DIGIT_TO_TRANSFER].clone().detach() # Shape ()\n",
    "\n",
    "    # Model A already has 10 output neurons. We overwrite the weights/bias\n",
    "    # corresponding to the TARGET_DIGIT_TO_TRANSFER (which is 4, index 4).\n",
    "    modified_model_A_sd['fc3.weight'][TARGET_DIGIT_TO_TRANSFER] = class4_weight_B.to(DEVICE)\n",
    "    modified_model_A_sd['fc3.bias'][TARGET_DIGIT_TO_TRANSFER] = class4_bias_B.to(DEVICE)\n",
    "    print(f\"  Class {TARGET_DIGIT_TO_TRANSFER} weight and bias copied from Model B to Model A's output layer.\")\n",
    "\n",
    "    # Load the modified state_dict into a new Model A instance\n",
    "    surgically_modified_model_A = SimpleNN().to(DEVICE)\n",
    "    surgically_modified_model_A.load_state_dict(modified_model_A_sd)\n",
    "    print(\"Surgically modified Model A created and loaded with new weights.\")\n",
    "\n",
    "    # --- Step 8: Sanity tests ---\n",
    "    print(\"\\nStep 8: Performing Sanity Tests on Surgically Modified Model A\")\n",
    "\n",
    "    # Evaluate on original A's digits (0,1,2,3)\n",
    "    acc_A_orig_digits = evaluate_model_accuracy(surgically_modified_model_A, DataLoader(eval_set_A_labels_test_dataset, BATCH_SIZE))\n",
    "    print(f\"  Surgically Modified Model A Accuracy on original digits ({CLASS1_LABELS}): {acc_A_orig_digits:.2f}%\")\n",
    "\n",
    "    # Evaluate on target digit (4)\n",
    "    acc_target_digit = evaluate_model_accuracy(surgically_modified_model_A, DataLoader(target_digit_test_dataset, BATCH_SIZE))\n",
    "    print(f\"  Surgically Modified Model A Accuracy on target digit ({TARGET_DIGIT_TO_TRANSFER}): {acc_target_digit:.2f}%\")\n",
    "\n",
    "    # Evaluate on out-of-class digit (5)\n",
    "    acc_ooc_digit = evaluate_model_accuracy(surgically_modified_model_A, DataLoader(ooc_digit_test_dataset, BATCH_SIZE))\n",
    "    print(f\"  Surgically Modified Model A Accuracy on out-of-class digit ({OOC_DIGIT_TO_MONITOR}): {acc_ooc_digit:.2f}%\")\n",
    "\n",
    "    # For comparison, evaluate original Model A's performance\n",
    "    print(\"\\n--- Original Model A Performance (for comparison) ---\")\n",
    "    orig_A_acc_orig_digits = evaluate_model_accuracy(model_A, DataLoader(eval_set_A_labels_test_dataset, BATCH_SIZE))\n",
    "    orig_A_acc_target_digit = evaluate_model_accuracy(model_A, DataLoader(target_digit_test_dataset, BATCH_SIZE))\n",
    "    orig_A_acc_ooc_digit = evaluate_model_accuracy(model_A, DataLoader(ooc_digit_test_dataset, BATCH_SIZE))\n",
    "    print(f\"  Original Model A Accuracy on original digits ({CLASS1_LABELS}): {orig_A_acc_orig_digits:.2f}%\")\n",
    "    print(f\"  Original Model A Accuracy on target digit ({TARGET_DIGIT_TO_TRANSFER}): {orig_A_acc_target_digit:.2f}%\")\n",
    "    print(f\"  Original Model A Accuracy on out-of-class digit ({OOC_DIGIT_TO_MONITOR}): {orig_A_acc_ooc_digit:.2f}%\")\n",
    "\n",
    "    print(\"\\nModel surgery pipeline complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_model_surgery_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a different approach - let's improve the surgical method itself\n",
    "print(\"--- Improved Model Surgery Attempt ---\")\n",
    "\n",
    "# Let's try a more aggressive approach and also check the alignment quality\n",
    "def improved_model_surgery():\n",
    "    # Check alignment quality first\n",
    "    print(\"Checking alignment quality...\")\n",
    "    sample_features_A = H_A_shared[:100]  # Take first 100 samples\n",
    "    sample_features_B = H_B_shared[:100]\n",
    "    \n",
    "    # Apply alignment and check reconstruction error\n",
    "    aligned_B_features = sample_features_B @ R.cpu()\n",
    "    reconstruction_error = torch.norm(sample_features_A - aligned_B_features) / torch.norm(sample_features_A)\n",
    "    print(f\"Reconstruction error after alignment: {reconstruction_error:.4f}\")\n",
    "    \n",
    "    # Try multiple approaches for better surgery\n",
    "    print(\"\\nTrying improved surgical approaches...\")\n",
    "    \n",
    "    # Approach 1: More aggressive alpha and more rows\n",
    "    ALPHA_IMPROVED = 1.5\n",
    "    K_ROWS_IMPROVED = 3\n",
    "    \n",
    "    # Get fresh copy of model A\n",
    "    improved_model_A = SimpleNN().to(DEVICE) \n",
    "    improved_model_A.load_state_dict(model_A.state_dict())\n",
    "    \n",
    "    # Apply more aggressive surgery\n",
    "    with torch.no_grad():\n",
    "        # Get current classifier weights\n",
    "        classifier_weights = improved_model_A.fc3.weight.data\n",
    "        \n",
    "        # Find rows with most negative cosine similarity (top 3 this time)\n",
    "        cosine_sims = torch.nn.functional.cosine_similarity(\n",
    "            classifier_weights, W_tilde_4.unsqueeze(0), dim=1\n",
    "        )\n",
    "        bottom_k_indices = torch.argsort(cosine_sims)[:K_ROWS_IMPROVED]\n",
    "        \n",
    "        print(f\"Modifying rows: {bottom_k_indices.tolist()}\")\n",
    "        print(f\"Their cosine similarities: {cosine_sims[bottom_k_indices].tolist()}\")\n",
    "        \n",
    "        # Apply surgical edit with higher alpha\n",
    "        for idx in bottom_k_indices:\n",
    "            classifier_weights[idx] += ALPHA_IMPROVED * W_tilde_4\n",
    "        \n",
    "        # Also directly set the row for digit 4 to be the transported probe + original row\n",
    "        classifier_weights[4] = model_B.fc3.weight.data[4] + 0.3 * W_tilde_4\n",
    "        improved_model_A.fc3.bias.data[4] = model_B.fc3.bias.data[4]\n",
    "    \n",
    "    # Test improved model\n",
    "    print(\"\\nTesting improved surgical model...\")\n",
    "    acc_orig = evaluate_model_accuracy(improved_model_A, DataLoader(eval_set_A_labels_test_dataset, BATCH_SIZE))\n",
    "    acc_target = evaluate_model_accuracy(improved_model_A, DataLoader(target_digit_test_dataset, BATCH_SIZE))\n",
    "    acc_ooc = evaluate_model_accuracy(improved_model_A, DataLoader(ooc_digit_test_dataset, BATCH_SIZE))\n",
    "    \n",
    "    print(f\"Improved Model - Original digits accuracy: {acc_orig:.2f}%\")\n",
    "    print(f\"Improved Model - Target digit 4 accuracy: {acc_target:.2f}%\")\n",
    "    print(f\"Improved Model - OOC digit 5 accuracy: {acc_ooc:.2f}%\")\n",
    "    \n",
    "    return improved_model_A\n",
    "\n",
    "# Run improved surgery\n",
    "improved_model = improved_model_surgery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Let's check the probe training and model predictions more carefully\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def debug_probe_performance():\n",
    "    \"\"\"Debug the probe training to see if it's actually learning the digit-4 pattern\"\"\"\n",
    "    print(\"--- Debugging Probe Performance ---\")\n",
    "    \n",
    "    # Re-create the probe training data for evaluation\n",
    "    probe_data_B_raw = []\n",
    "    probe_labels_B_binary = []\n",
    "    \n",
    "    for img, label in probe_train_dataset_B:\n",
    "        probe_data_B_raw.append(img)\n",
    "        probe_labels_B_binary.append(1 if label == TARGET_DIGIT_TO_TRANSFER else 0)\n",
    "\n",
    "    probe_data_B_raw = torch.stack(probe_data_B_raw)\n",
    "    probe_labels_B_binary = torch.tensor(probe_labels_B_binary, dtype=torch.float32)\n",
    "\n",
    "    # Extract features using Model B\n",
    "    model_B.eval()\n",
    "    with torch.no_grad():\n",
    "        probe_features = model_B.get_hidden_features(probe_data_B_raw.to(DEVICE))\n",
    "    \n",
    "    # Test probe predictions\n",
    "    probe_net.eval()\n",
    "    with torch.no_grad():\n",
    "        probe_logits = probe_net(probe_features).squeeze()\n",
    "        probe_probs = torch.sigmoid(probe_logits)\n",
    "        probe_preds = (probe_probs > 0.5).float()\n",
    "    \n",
    "    # Calculate probe accuracy\n",
    "    accuracy = (probe_preds.cpu() == probe_labels_B_binary).float().mean()\n",
    "    print(f\"Probe accuracy on training data: {accuracy:.3f}\")\n",
    "    \n",
    "    # Check distribution of predictions for each digit\n",
    "    digit_4_mask = probe_labels_B_binary == 1\n",
    "    digit_not4_mask = probe_labels_B_binary == 0\n",
    "    \n",
    "    print(f\"Probe predictions for digit 4 (should be high): {probe_probs[digit_4_mask].mean():.3f}\")\n",
    "    print(f\"Probe predictions for non-4 digits (should be low): {probe_probs[digit_not4_mask].mean():.3f}\")\n",
    "    \n",
    "    return probe_features, probe_labels_B_binary, probe_probs\n",
    "\n",
    "def debug_model_predictions():\n",
    "    \"\"\"Debug what the surgically modified model is actually predicting\"\"\"\n",
    "    print(\"\\n--- Debugging Model Predictions ---\")\n",
    "    \n",
    "    # Test on a few examples of digit 4\n",
    "    digit_4_loader = DataLoader(target_digit_test_dataset, batch_size=10, shuffle=False)\n",
    "    \n",
    "    surgically_modified_model_A.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(digit_4_loader):\n",
    "            if batch_idx > 0:  # Only check first batch\n",
    "                break\n",
    "                \n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            \n",
    "            # Get predictions\n",
    "            logits = surgically_modified_model_A(data)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            print(f\"Target labels: {target[:5].cpu()}\")\n",
    "            print(f\"Predicted labels: {preds[:5].cpu()}\")\n",
    "            print(f\"Max probabilities: {probs.max(dim=1)[0][:5].cpu()}\")\n",
    "            print(f\"Prob for digit 4: {probs[:5, 4].cpu()}\")\n",
    "            \n",
    "            # Also check what original Model A would predict\n",
    "            original_logits = model_A(data)\n",
    "            original_preds = torch.argmax(original_logits, dim=1)\n",
    "            print(f\"Original Model A predictions: {original_preds[:5].cpu()}\")\n",
    "\n",
    "# Run debugging\n",
    "probe_features, probe_labels, probe_probs = debug_probe_performance()\n",
    "debug_model_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
