#!/bin/bash

# Comprehensive 4-Quadrant Architecture Transfer Comparison
# Tests all combinations: Deep‚ÜíDeep, Wide‚ÜíWide, Wide‚ÜíDeep, Deep‚ÜíWide

echo "üèõÔ∏è COMPREHENSIVE 4-QUADRANT ARCHITECTURE COMPARISON"
echo "===================================================="
echo "Testing ALL architecture transfer combinations:"
echo "1. DeepNN ‚Üí DeepNN (same deep architecture)"
echo "2. WideNN ‚Üí WideNN (same wide architecture)" 
echo "3. WideNN ‚Üí DeepNN (wide to deep transfer)"
echo "4. DeepNN ‚Üí WideNN (deep to wide transfer)"
echo ""
echo "Configuration:"
echo "- 10 different seeds per quadrant (40 total experiments)"
echo "- Fixed rho = 0.5 (balanced blending)"
echo "- FIXED: Proper seed-based random data sampling"
echo "- Clean setup: Source {2,3,4,5,6,7} ‚Üí Target {0,1,2,3,4,5}"
echo "- Transfer class: 6"
echo ""

# Configuration
SEEDS=(42 123 456 789 101112 131415 161718 192021 222324 252627)  # 10 different seeds
MAX_EPOCHS=3  # Faster for comprehensive test
SAE_EPOCHS=20
BATCH_SIZE=32
LEARNING_RATE=0.001
CONCEPT_DIM=24

echo "üìÅ Creating comprehensive results directory..."
mkdir -p experiment_results/comprehensive_architecture_comparison/{deep_to_deep,wide_to_wide,wide_to_deep,deep_to_wide}
mkdir -p logs

echo ""
echo "üß™ RUNNING COMPREHENSIVE ARCHITECTURE COMPARISON"
echo "==============================================="

# Configuration JSON
CONFIG_JSON="{\"max_epochs\": $MAX_EPOCHS, \"sae_epochs\": $SAE_EPOCHS, \"batch_size\": $BATCH_SIZE, \"learning_rate\": $LEARNING_RATE, \"concept_dim\": $CONCEPT_DIM, \"transfer_class\": 6}"

# All four architecture combinations
declare -a ARCH_COMBOS=("deep_to_deep" "wide_to_wide" "wide_to_deep" "deep_to_wide")

TOTAL_EXPERIMENTS=$((${#ARCH_COMBOS[@]} * ${#SEEDS[@]}))
CURRENT_EXPERIMENT=0
SUCCESSFUL_EXPERIMENTS=0

echo "üìä Comprehensive Architecture Comparison Plan:"
echo "   - Architecture combinations: ${#ARCH_COMBOS[@]}"
echo "   - Seeds per combination: ${#SEEDS[@]}"
echo "   - Total experiments: $TOTAL_EXPERIMENTS"
echo "   - Using FIXED experimental framework with proper seed-based data sampling"
echo ""

# Create comprehensive experiment runner
cat > run_single_comprehensive_arch_experiment.py << 'EOF'
#!/usr/bin/env python3
"""
Comprehensive architecture comparison using the fixed experimental framework.
Tests all four architecture transfer combinations.
"""

import torch
import torch.nn as nn
import json
import sys
import copy
import numpy as np
from datetime import datetime

from architectures import WideNN, DeepNN
from experimental_framework import MNISTDataManager, ExperimentConfig, ModelTrainer
from robust_balanced_transfer import RobustBalancedTransferSystem

class ComprehensiveArchWrappedModel(nn.Module):
    """Wrapper for evaluation in comprehensive architecture comparison."""
    def __init__(self, base_model, transfer_system, transfer_class):
        super().__init__()
        self.base_model = base_model
        self.transfer_system = transfer_system
        self.transfer_class = transfer_class
    
    def forward(self, x):
        if self.transfer_system is None:
            return self.base_model(x)
        
        x_flat = x.view(x.size(0), -1)
        
        if hasattr(self.transfer_system, 'transfer_concept'):
            try:
                return self.transfer_system.transfer_concept(x_flat, self.transfer_class)
            except:
                pass
        
        return self.base_model(x_flat)

def measure_accuracy(model, data_loader, target_classes):
    """Simple accuracy measurement."""
    model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for data, labels in data_loader:
            data = data.view(data.size(0), -1)
            
            # Filter for target classes
            mask = torch.tensor([label.item() in target_classes for label in labels])
            if mask.sum() == 0:
                continue
            
            filtered_data = data[mask]
            filtered_labels = labels[mask]
            
            outputs = model(filtered_data)
            _, predicted = torch.max(outputs, 1)
            
            for pred, true in zip(predicted, filtered_labels):
                if pred.item() == true.item():
                    correct += 1
                total += 1
    
    return correct / total if total > 0 else 0.0

def get_architecture_models(arch_combo):
    """Get source and target models for architecture combination."""
    if arch_combo == "deep_to_deep":
        return DeepNN(), DeepNN(), "DeepNN ‚Üí DeepNN"
    elif arch_combo == "wide_to_wide":
        return WideNN(), WideNN(), "WideNN ‚Üí WideNN"  
    elif arch_combo == "wide_to_deep":
        return WideNN(), DeepNN(), "WideNN ‚Üí DeepNN"
    elif arch_combo == "deep_to_wide":
        return DeepNN(), WideNN(), "DeepNN ‚Üí WideNN"
    else:
        raise ValueError(f"Unknown architecture combination: {arch_combo}")

def run_comprehensive_experiment(arch_combo, seed, config_params):
    """Run comprehensive architecture experiment."""
    
    print(f"üèõÔ∏è Running COMPREHENSIVE {arch_combo} experiment (seed={seed})")
    
    # Set seed properly
    torch.manual_seed(seed)
    np.random.seed(seed)
    
    # Setup
    source_classes = {2, 3, 4, 5, 6, 7}
    target_classes = {0, 1, 2, 3, 4, 5}
    transfer_class = 6
    specificity_class = 7
    
    config = ExperimentConfig(
        seed=seed,
        max_epochs=config_params['max_epochs'],
        batch_size=config_params['batch_size'],
        learning_rate=config_params['learning_rate'],
        concept_dim=config_params['concept_dim'],
        device='cpu'
    )
    
    try:
        # Create data (now uses proper seed-based sampling!)
        data_manager = MNISTDataManager(config)
        trainer = ModelTrainer(config)
        
        source_train_loader, target_train_loader, source_test_loader, target_test_loader = \
            data_manager.get_data_loaders(source_classes, target_classes)
        
        # Get architecture-specific models
        source_model, target_model, arch_desc = get_architecture_models(arch_combo)
        
        # Train models
        trained_source, source_acc = trainer.train_model(source_model, source_train_loader, source_test_loader)
        trained_target, target_acc = trainer.train_model(target_model, target_train_loader, target_test_loader)
        
        print(f"   üèóÔ∏è  {arch_desc}")
        print(f"   ‚úÖ Models trained: Source={source_acc:.3f}, Target={target_acc:.3f}")
        
        # Critical: Clone before transfer
        target_before_transfer = copy.deepcopy(trained_target)
        
        # Setup transfer with fixed rho=0.5
        transfer_system = RobustBalancedTransferSystem(
            source_model=trained_source,
            target_model=trained_target,
            source_classes=source_classes,
            target_classes=target_classes,
            concept_dim=config.concept_dim,
            device=config.device
        )
        
        transfer_system.fit(source_train_loader, target_train_loader, sae_epochs=config_params['sae_epochs'])
        transfer_system.setup_injection_system(transfer_class, source_train_loader, target_train_loader)
        
        # Evaluate
        target_after = ComprehensiveArchWrappedModel(trained_target, transfer_system, transfer_class)
        
        # Comprehensive accuracy measurements
        source_original = measure_accuracy(trained_source, source_test_loader, source_classes)
        source_transfer_class = measure_accuracy(trained_source, source_test_loader, {transfer_class})
        source_specificity_class = measure_accuracy(trained_source, source_test_loader, {specificity_class})
        
        target_before_original = measure_accuracy(target_before_transfer, target_test_loader, target_classes)
        target_before_transfer_class = measure_accuracy(target_before_transfer, source_test_loader, {transfer_class})
        target_before_specificity_class = measure_accuracy(target_before_transfer, source_test_loader, {specificity_class})
        
        target_after_original = measure_accuracy(target_after, target_test_loader, target_classes)
        target_after_transfer_class = measure_accuracy(target_after, source_test_loader, {transfer_class})
        target_after_specificity_class = measure_accuracy(target_after, source_test_loader, {specificity_class})
        
        # Calculate key metrics
        transfer_improvement = target_after_transfer_class - target_before_transfer_class
        knowledge_preservation = target_after_original
        transfer_effectiveness = target_after_transfer_class
        transfer_specificity = target_after_specificity_class
        
        print(f"   üìä Results Table:")
        print(f"      | Model           | Original | Class 6 | Class 7 |")
        print(f"      | Source          | {source_original:7.1%} | {source_transfer_class:6.1%} | {source_specificity_class:6.1%} |")
        print(f"      | Target (Before) | {target_before_original:7.1%} | {target_before_transfer_class:6.1%} | {target_before_specificity_class:6.1%} |")
        print(f"      | Target (After)  | {target_after_original:7.1%} | {target_after_transfer_class:6.1%} | {target_after_specificity_class:6.1%} |")
        print(f"   üéØ Key Metrics:")
        print(f"      Transfer improvement: {transfer_improvement:.1%}")
        print(f"      Knowledge preservation: {knowledge_preservation:.1%}")
        print(f"      Transfer effectiveness: {transfer_effectiveness:.1%}")
        
        # Validate clean setup
        if target_before_transfer_class > 0.3 or target_before_specificity_class > 0.3:
            print(f"   ‚ö†Ô∏è  WARNING: Possible data leakage detected!")
        else:
            print(f"   ‚úÖ Clean experimental setup validated")
        
        # Return comprehensive results
        return {
            'experiment_id': f"comprehensive_{arch_combo}_seed_{seed}",
            'architecture_combination': arch_combo,
            'architecture_description': arch_desc,
            'seed': seed,
            'timestamp': datetime.now().isoformat(),
            'experimental_setup': {
                'source_classes': sorted(source_classes),
                'target_classes': sorted(target_classes),
                'transfer_class': transfer_class,
                'specificity_class': specificity_class
            },
            'model_accuracies': {
                'source': source_acc,
                'target': target_acc
            },
            'detailed_results': {
                'source_original': source_original,
                'source_transfer_class': source_transfer_class,
                'source_specificity_class': source_specificity_class,
                'target_before_original': target_before_original,
                'target_before_transfer_class': target_before_transfer_class,
                'target_before_specificity_class': target_before_specificity_class,
                'target_after_original': target_after_original,
                'target_after_transfer_class': target_after_transfer_class,
                'target_after_specificity_class': target_after_specificity_class
            },
            'key_metrics': {
                'transfer_improvement': transfer_improvement,
                'knowledge_preservation': knowledge_preservation,
                'transfer_effectiveness': transfer_effectiveness,
                'transfer_specificity': transfer_specificity
            },
            'validation': {
                'data_leakage_detected': (target_before_transfer_class > 0.3 or target_before_specificity_class > 0.3),
                'transfer_class_before': target_before_transfer_class,
                'specificity_class_before': target_before_specificity_class
            }
        }
        
    except Exception as e:
        print(f"   ‚ùå Failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    if len(sys.argv) != 4:
        print("Usage: python run_single_comprehensive_arch_experiment.py <arch_combo> <seed> <config_json>")
        sys.exit(1)
    
    arch_combo = sys.argv[1]
    seed = int(sys.argv[2])
    config_params = json.loads(sys.argv[3])
    
    result = run_comprehensive_experiment(arch_combo, seed, config_params)
    
    if result:
        print(json.dumps(result, indent=2))
    else:
        sys.exit(1)

if __name__ == "__main__":
    main()
EOF

# Run all experiments
for arch_combo in "${ARCH_COMBOS[@]}"; do
    echo ""
    echo "üèóÔ∏è  ARCHITECTURE COMBINATION: $arch_combo"
    echo "========================================="
    
    for seed in "${SEEDS[@]}"; do
        CURRENT_EXPERIMENT=$((CURRENT_EXPERIMENT + 1))
        
        echo ""
        echo "[$CURRENT_EXPERIMENT/$TOTAL_EXPERIMENTS] Running $arch_combo with seed $seed..."
        
        if python run_single_comprehensive_arch_experiment.py "$arch_combo" "$seed" "$CONFIG_JSON" > "logs/comprehensive_arch_${arch_combo}_seed_${seed}.json" 2> "logs/comprehensive_arch_${arch_combo}_seed_${seed}.log"; then
            
            result_file="experiment_results/comprehensive_architecture_comparison/$arch_combo/comprehensive_arch_${arch_combo}_seed_${seed}.json"
            cp "logs/comprehensive_arch_${arch_combo}_seed_${seed}.json" "$result_file"
            
            SUCCESSFUL_EXPERIMENTS=$((SUCCESSFUL_EXPERIMENTS + 1))
            echo "   ‚úÖ Success"
        else
            echo "   ‚ùå Failed - check logs"
        fi
    done
done

echo ""
echo "üìä ANALYZING COMPREHENSIVE RESULTS"
echo "=================================="

# Comprehensive analysis
cat > analyze_comprehensive_results.py << 'EOF'
#!/usr/bin/env python3
import json
import statistics
from pathlib import Path
from datetime import datetime

def analyze_comprehensive_results():
    results = {
        'deep_to_deep': [],
        'wide_to_wide': [], 
        'wide_to_deep': [],
        'deep_to_wide': []
    }
    
    base_path = Path('experiment_results/comprehensive_architecture_comparison')
    for arch_combo in results.keys():
        result_dir = base_path / arch_combo
        if result_dir.exists():
            for result_file in result_dir.glob('*.json'):
                try:
                    with open(result_file, 'r') as f:
                        content = f.read()
                        json_start = content.find('{')
                        if json_start != -1:
                            data = json.loads(content[json_start:])
                            results[arch_combo].append(data)
                except Exception as e:
                    print(f"Warning: {result_file}: {e}")
    
    print("üèõÔ∏è COMPREHENSIVE 4-QUADRANT ARCHITECTURE COMPARISON RESULTS")
    print("=" * 70)
    
    # Summary table
    print(f"\nüìä RESULTS SUMMARY:")
    print(f"{'Architecture Combination':<25} {'Count':<6} {'Avg Effectiveness':<16} {'Avg Preservation':<16} {'Std Dev':<10}")
    print("-" * 85)
    
    summary_data = {}
    for arch_combo, arch_results in results.items():
        if arch_results:
            effectiveness_values = [r['key_metrics']['transfer_effectiveness'] for r in arch_results]
            preservation_values = [r['key_metrics']['knowledge_preservation'] for r in arch_results]
            
            avg_eff = statistics.mean(effectiveness_values)
            avg_pres = statistics.mean(preservation_values)
            std_eff = statistics.stdev(effectiveness_values) if len(effectiveness_values) > 1 else 0.0
            
            summary_data[arch_combo] = {
                'avg_effectiveness': avg_eff,
                'avg_preservation': avg_pres,
                'std_effectiveness': std_eff,
                'count': len(arch_results)
            }
            
            # Format architecture name
            arch_display = arch_combo.replace('_to_', ' ‚Üí ').replace('_', '').title()
            
            print(f"{arch_display:<25} {len(arch_results):<6} {avg_eff:<16.1%} {avg_pres:<16.1%} {std_eff:<10.1%}")
    
    # Detailed analysis by quadrant
    print(f"\nüìà DETAILED ANALYSIS BY QUADRANT:")
    print("=" * 50)
    
    for arch_combo, arch_results in results.items():
        if arch_results:
            arch_display = arch_combo.replace('_to_', ' ‚Üí ').replace('_', '').title()
            print(f"\nüèóÔ∏è  {arch_display}:")
            
            effectiveness_values = []
            preservation_values = []
            improvement_values = []
            
            for r in arch_results:
                seed = r['seed']
                eff = r['key_metrics']['transfer_effectiveness']
                pres = r['key_metrics']['knowledge_preservation']
                imp = r['key_metrics']['transfer_improvement']
                
                effectiveness_values.append(eff)
                preservation_values.append(pres)
                improvement_values.append(imp)
                
                print(f"   Seed {seed:>6}: {eff:.1%} effectiveness, {pres:.1%} preservation, {imp:+.1%} improvement")
            
            # Check for variation (verify seed fix works)
            unique_eff = len(set([round(x, 3) for x in effectiveness_values]))
            if unique_eff > 1:
                print(f"   ‚úÖ Shows proper seed variation: {unique_eff} unique effectiveness values")
            else:
                print(f"   ‚ùå No seed variation: identical results across seeds")
    
    # Find best and worst performing combinations
    if summary_data:
        best_combo = max(summary_data.keys(), key=lambda x: summary_data[x]['avg_effectiveness'])
        worst_combo = min(summary_data.keys(), key=lambda x: summary_data[x]['avg_effectiveness'])
        
        best_eff = summary_data[best_combo]['avg_effectiveness']
        worst_eff = summary_data[worst_combo]['avg_effectiveness']
        
        print(f"\nüèÜ BEST PERFORMING COMBINATION:")
        print(f"   {best_combo.replace('_to_', ' ‚Üí ').replace('_', '').title()}: {best_eff:.1%} average effectiveness")
        
        print(f"\nüìâ WORST PERFORMING COMBINATION:")
        print(f"   {worst_combo.replace('_to_', ' ‚Üí ').replace('_', '').title()}: {worst_eff:.1%} average effectiveness")
        
        print(f"\nüìä PERFORMANCE SPREAD:")
        print(f"   Range: {best_eff - worst_eff:.1%} difference between best and worst")
        
        # Architecture pattern analysis
        print(f"\nüîç ARCHITECTURE PATTERN ANALYSIS:")
        
        # Same vs Cross architecture comparison
        same_arch_combos = ['deep_to_deep', 'wide_to_wide']
        cross_arch_combos = ['wide_to_deep', 'deep_to_wide']
        
        same_arch_avg = statistics.mean([summary_data[combo]['avg_effectiveness'] 
                                       for combo in same_arch_combos if combo in summary_data])
        cross_arch_avg = statistics.mean([summary_data[combo]['avg_effectiveness'] 
                                        for combo in cross_arch_combos if combo in summary_data])
        
        print(f"   Same Architecture Average:  {same_arch_avg:.1%}")
        print(f"   Cross Architecture Average: {cross_arch_avg:.1%}")
        print(f"   Cross Architecture Advantage: {cross_arch_avg - same_arch_avg:+.1%}")
        
        # Deep vs Wide analysis
        deep_source_avg = statistics.mean([summary_data[combo]['avg_effectiveness'] 
                                         for combo in ['deep_to_deep', 'deep_to_wide'] if combo in summary_data])
        wide_source_avg = statistics.mean([summary_data[combo]['avg_effectiveness'] 
                                         for combo in ['wide_to_wide', 'wide_to_deep'] if combo in summary_data])
        
        deep_target_avg = statistics.mean([summary_data[combo]['avg_effectiveness'] 
                                         for combo in ['deep_to_deep', 'wide_to_deep'] if combo in summary_data])
        wide_target_avg = statistics.mean([summary_data[combo]['avg_effectiveness'] 
                                         for combo in ['wide_to_wide', 'deep_to_wide'] if combo in summary_data])
        
        print(f"\nüéØ SOURCE ARCHITECTURE EFFECT:")
        print(f"   Deep Source Average:  {deep_source_avg:.1%}")
        print(f"   Wide Source Average:  {wide_source_avg:.1%}")
        print(f"   Wide Source Advantage: {wide_source_avg - deep_source_avg:+.1%}")
        
        print(f"\nüéØ TARGET ARCHITECTURE EFFECT:")
        print(f"   Deep Target Average:  {deep_target_avg:.1%}")
        print(f"   Wide Target Average:  {wide_target_avg:.1%}")
        print(f"   Wide Target Advantage: {wide_target_avg - deep_target_avg:+.1%}")
    
    # Generate comprehensive report
    report_path = Path('experiment_results/COMPREHENSIVE_ARCHITECTURE_COMPARISON.md')
    with open(report_path, 'w') as f:
        f.write(f"""# Comprehensive 4-Quadrant Architecture Comparison

**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Experimental Design

- **Architecture Combinations Tested:** 4 quadrants
  - DeepNN ‚Üí DeepNN (same deep architecture)
  - WideNN ‚Üí WideNN (same wide architecture)  
  - WideNN ‚Üí DeepNN (wide to deep transfer)
  - DeepNN ‚Üí WideNN (deep to wide transfer)
- **Experiments per combination:** 10 (different seeds)
- **Total experiments:** 40
- **Fixed parameters:** rho=0.5, clean class splits
- **Seed fix applied:** Proper random data sampling

## Results Summary

| Architecture Combination | Avg Effectiveness | Avg Preservation | Std Dev |
|--------------------------|-------------------|------------------|---------|
""")
        
        for arch_combo in ['deep_to_deep', 'wide_to_wide', 'wide_to_deep', 'deep_to_wide']:
            if arch_combo in summary_data:
                data = summary_data[arch_combo]
                arch_display = arch_combo.replace('_to_', ' ‚Üí ').replace('_', ' ').title()
                f.write(f"| {arch_display} | {data['avg_effectiveness']:.1%} | {data['avg_preservation']:.1%} | {data['std_effectiveness']:.1%} |\n")
        
        if summary_data:
            f.write(f"""

## Key Findings

- **Best Performing:** {best_combo.replace('_to_', ' ‚Üí ').replace('_', ' ').title()} ({best_eff:.1%})
- **Worst Performing:** {worst_combo.replace('_to_', ' ‚Üí ').replace('_', ' ').title()} ({worst_eff:.1%})
- **Performance Range:** {best_eff - worst_eff:.1%}

## Architecture Pattern Analysis

- **Same vs Cross Architecture:**
  - Same Architecture: {same_arch_avg:.1%}
  - Cross Architecture: {cross_arch_avg:.1%}
  - Cross Advantage: {cross_arch_avg - same_arch_avg:+.1%}

- **Source Architecture Effect:**
  - Deep Source: {deep_source_avg:.1%}
  - Wide Source: {wide_source_avg:.1%}
  - Wide Source Advantage: {wide_source_avg - deep_source_avg:+.1%}

- **Target Architecture Effect:**
  - Deep Target: {deep_target_avg:.1%}
  - Wide Target: {wide_target_avg:.1%}
  - Wide Target Advantage: {wide_target_avg - deep_target_avg:+.1%}

## Conclusion

This comprehensive analysis provides insights into how architecture choice affects neural concept transfer across all possible combinations of deep and wide networks.
""")
    
    print(f"\nüìÑ Comprehensive analysis report saved to: {report_path}")

if __name__ == "__main__":
    analyze_comprehensive_results()
EOF

python analyze_comprehensive_results.py

echo ""
echo "üéâ COMPREHENSIVE ARCHITECTURE COMPARISON COMPLETE!"
echo "================================================="
echo ""
echo "üìä Final Statistics:"
echo "   - Total experiments: $TOTAL_EXPERIMENTS"
echo "   - Successful: $SUCCESSFUL_EXPERIMENTS"
echo "   - Architecture combinations tested: 4"
echo "   - Experiments per combination: 10"
echo ""
echo "üîß EXPERIMENT DESIGN:"
echo "   ‚úÖ DeepNN ‚Üí DeepNN (same deep)"
echo "   ‚úÖ WideNN ‚Üí WideNN (same wide)"
echo "   ‚úÖ WideNN ‚Üí DeepNN (wide to deep)" 
echo "   ‚úÖ DeepNN ‚Üí WideNN (deep to wide)"
echo "   ‚úÖ Fixed seed-based random data sampling"
echo "   ‚úÖ 10 different seeds per combination"
echo ""
echo "üìÅ Results saved to: experiment_results/comprehensive_architecture_comparison/"
echo "üìÑ Analysis report: experiment_results/COMPREHENSIVE_ARCHITECTURE_COMPARISON.md"

# Cleanup
rm -f run_single_comprehensive_arch_experiment.py analyze_comprehensive_results.py