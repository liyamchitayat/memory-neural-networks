#!/usr/bin/env python3
"""
Spatial Relationship Transfer: Preserve spatial relationships between digits 2,4 and 3,4
Analyze representation similarity and maintain geometric structure in concept space
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
import numpy as np
import random
import os
from scipy.linalg import orthogonal_procrustes
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA

print("=== SPATIAL RELATIONSHIP TRANSFER ===")
print("Analyzing representation similarity and preserving spatial relationships\n")

DEVICE = torch.device("cuda" if torch.cuda.is_available() else ("mps" if torch.backends.mps.is_available() else "cpu"))
print(f"Using device: {DEVICE}")

class WideNN(nn.Module):
    """Wide architecture: 784->512->128->10"""
    def __init__(self):
        super(WideNN, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 512)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(512, 128)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(128, 10)
        
    def forward(self, x):
        x = x.view(-1, 28 * 28)
        x = self.fc1(x); x = self.relu1(x)
        x = self.fc2(x); x = self.relu2(x)
        x = self.fc3(x)
        return x
    
    def get_features(self, x):
        """Get penultimate layer features"""
        x = x.view(-1, 28 * 28)
        x = self.fc1(x); x = self.relu1(x)
        x = self.fc2(x); x = self.relu2(x)
        return x

class DeepNN(nn.Module):
    """Deep architecture: 784->256->256->128->10"""
    def __init__(self):
        super(DeepNN, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 256)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(256, 256)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(256, 128)
        self.relu3 = nn.ReLU()
        self.fc4 = nn.Linear(128, 10)
        
    def forward(self, x):
        x = x.view(-1, 28 * 28)
        x = self.fc1(x); x = self.relu1(x)
        x = self.fc2(x); x = self.relu2(x)
        x = self.fc3(x); x = self.relu3(x)
        x = self.fc4(x)
        return x
        
    def get_features(self, x):
        """Get penultimate layer features"""
        x = x.view(-1, 28 * 28)
        x = self.fc1(x); x = self.relu1(x)
        x = self.fc2(x); x = self.relu2(x)
        x = self.fc3(x); x = self.relu3(x)
        return x

class ConceptSAE(nn.Module):
    def __init__(self, input_dim, concept_dim=24, sparsity_weight=0.05):
        super(ConceptSAE, self).__init__()
        self.input_dim = input_dim
        self.concept_dim = concept_dim
        self.sparsity_weight = sparsity_weight
        
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, concept_dim * 2),
            nn.ReLU(),
            nn.Linear(concept_dim * 2, concept_dim),
            nn.ReLU()
        )
        
        self.decoder = nn.Sequential(
            nn.Linear(concept_dim, concept_dim * 2),
            nn.ReLU(), 
            nn.Linear(concept_dim * 2, input_dim)
        )
        
    def forward(self, x):
        concepts = self.encoder(x)
        reconstructed = self.decoder(concepts)
        return concepts, reconstructed
    
    def encode(self, x):
        return self.encoder(x)
    
    def decode(self, concepts):
        return self.decoder(concepts)

def create_subset(dataset, labels_to_include):
    indices = [i for i, (_, label) in enumerate(dataset) if label in labels_to_include]
    return Subset(dataset, indices)

def train_model(model, train_dataset, num_epochs=6):
    """Train a model on given dataset"""
    print(f"Training {model.__class__.__name__}...")
    
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
    
    model.train()
    for epoch in range(num_epochs):
        epoch_loss = 0
        for data, target in train_loader:
            data, target = data.to(DEVICE), target.to(DEVICE)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        
        if epoch % 2 == 0:
            avg_loss = epoch_loss / len(train_loader)
            print(f"  Epoch {epoch}: Loss = {avg_loss:.4f}")
    
    model.eval()
    return model

def train_concept_sae(model, dataset, concept_dim=24, epochs=20):
    model.eval()
    loader = DataLoader(dataset, batch_size=128, shuffle=False)
    all_features = []
    
    with torch.no_grad():
        for data, _ in loader:
            data = data.to(DEVICE)
            features = model.get_features(data).cpu()
            all_features.append(features)
    
    all_features = torch.cat(all_features)
    input_dim = all_features.shape[1]
    
    print(f"Training SAE: {input_dim}D â†’ {concept_dim}D concepts on {len(all_features)} samples")
    
    sae = ConceptSAE(input_dim, concept_dim).to(DEVICE)
    optimizer = optim.Adam(sae.parameters(), lr=0.001)
    
    feature_dataset = torch.utils.data.TensorDataset(all_features.to(DEVICE))
    feature_loader = DataLoader(feature_dataset, batch_size=128, shuffle=True)
    
    sae.train()
    for epoch in range(epochs):
        epoch_loss = 0
        for batch_data in feature_loader:
            features = batch_data[0]
            optimizer.zero_grad()
            
            concepts, reconstructed = sae(features)
            recon_loss = nn.MSELoss()(reconstructed, features)
            sparsity_loss = torch.mean(torch.abs(concepts))
            total_loss = recon_loss + sae.sparsity_weight * sparsity_loss
            
            total_loss.backward()
            optimizer.step()
            epoch_loss += total_loss.item()
        
        if epoch % 5 == 4:
            print(f"  SAE Epoch {epoch+1}: Loss={epoch_loss/len(feature_loader):.4f}")
    
    return sae

def extract_digit_concepts(model, sae, dataset, target_digits):
    """Extract concept representations for specific digits"""
    model.eval()
    sae.eval()
    
    concepts_by_digit = {}
    loader = DataLoader(dataset, batch_size=64, shuffle=False)
    
    with torch.no_grad():
        for data, labels in loader:
            data = data.to(DEVICE)
            features = model.get_features(data)
            concepts = sae.encode(features).cpu()
            
            for i, label in enumerate(labels):
                if label.item() in target_digits:
                    if label.item() not in concepts_by_digit:
                        concepts_by_digit[label.item()] = []
                    concepts_by_digit[label.item()].append(concepts[i])
    
    # Convert to tensors and compute means
    for digit in concepts_by_digit:
        if concepts_by_digit[digit]:
            concepts_by_digit[digit] = torch.stack(concepts_by_digit[digit])
        else:
            concepts_by_digit[digit] = torch.empty(0, sae.concept_dim)
    
    return concepts_by_digit

def analyze_representation_similarity(model_A, model_B, shared_dataset):
    """Analyze how similar representations of digits 2,3 are between models"""
    print("\n=== REPRESENTATION SIMILARITY ANALYSIS ===")
    
    model_A.eval()
    model_B.eval()
    
    loader = DataLoader(shared_dataset, batch_size=64, shuffle=False)
    
    features_A = []
    features_B = []
    labels = []
    
    with torch.no_grad():
        for data, target in loader:
            data = data.to(DEVICE)
            
            feat_A = model_A.get_features(data).cpu()
            feat_B = model_B.get_features(data).cpu()
            
            features_A.append(feat_A)
            features_B.append(feat_B)
            labels.extend(target.numpy())
    
    features_A = torch.cat(features_A)
    features_B = torch.cat(features_B)
    labels = np.array(labels)
    
    print(f"Feature shapes: A={features_A.shape}, B={features_B.shape}")
    
    # Overall similarity
    feature_sim = torch.cosine_similarity(features_A, features_B, dim=1)
    print(f"Overall cosine similarity: {feature_sim.mean():.4f} Â± {feature_sim.std():.4f}")
    
    # Per-digit similarity
    digit_similarities = {}
    for digit in [2, 3]:
        mask = labels == digit
        digit_sim = feature_sim[mask]
        digit_similarities[digit] = digit_sim.mean().item()
        print(f"  Digit {digit} similarity: {digit_sim.mean():.4f} Â± {digit_sim.std():.4f}")
    
    # Feature magnitude comparison
    mag_A = torch.norm(features_A, dim=1)
    mag_B = torch.norm(features_B, dim=1)
    print(f"Feature magnitudes: A={mag_A.mean():.3f}Â±{mag_A.std():.3f}, B={mag_B.mean():.3f}Â±{mag_B.std():.3f}")
    
    return digit_similarities, features_A, features_B, labels

def analyze_spatial_relationships(concepts_B):
    """Analyze spatial relationships in source model B"""
    print("\n=== SPATIAL RELATIONSHIP ANALYSIS ===")
    
    # Compute centroids
    centroids = {}
    for digit in [2, 3, 4, 5]:
        if digit in concepts_B and len(concepts_B[digit]) > 0:
            centroids[digit] = concepts_B[digit].mean(dim=0)
    
    # Compute pairwise distances and relationships
    relationships = {}
    print("Spatial relationships in Model B:")
    
    for digit_a in [2, 3]:
        for digit_b in [4, 5]:
            if digit_a in centroids and digit_b in centroids:
                # Vector from digit_a to digit_b
                relationship_vector = centroids[digit_b] - centroids[digit_a]
                distance = torch.norm(relationship_vector).item()
                
                relationships[f"{digit_a}â†’{digit_b}"] = {
                    'vector': relationship_vector,
                    'distance': distance
                }
                
                print(f"  Distance {digit_a}â†’{digit_b}: {distance:.4f}")
    
    # Key relationships for transfer
    if "2â†’4" in relationships and "3â†’4" in relationships:
        rel_2_4 = relationships["2â†’4"]['vector']
        rel_3_4 = relationships["3â†’4"]['vector']
        
        # Angle between relationships
        cos_angle = torch.dot(rel_2_4, rel_3_4) / (torch.norm(rel_2_4) * torch.norm(rel_3_4))
        angle = torch.acos(torch.clamp(cos_angle, -1, 1)) * 180 / np.pi
        
        print(f"  Angle between 2â†’4 and 3â†’4 relationships: {angle:.1f}Â°")
        
        relationships['target_relationships'] = {
            '2â†’4': rel_2_4,
            '3â†’4': rel_3_4,
            'angle': angle.item()
        }
    
    return relationships, centroids

def create_spatial_transfer_model(target_model, target_sae, spatial_relationships, target_concepts):
    """Create model that preserves spatial relationships"""
    print("\n=== CREATING SPATIAL TRANSFER MODEL ===")
    
    target_centroids = {}
    for digit in [0, 1, 2, 3]:
        if digit in target_concepts and len(target_concepts[digit]) > 0:
            target_centroids[digit] = target_concepts[digit].mean(dim=0)
    
    # Calculate where digit 4 should be placed to preserve relationships
    rel_2_4 = spatial_relationships['target_relationships']['2â†’4'].to(DEVICE)
    rel_3_4 = spatial_relationships['target_relationships']['3â†’4'].to(DEVICE)
    
    # Two possible positions for digit 4
    pos_4_from_2 = target_centroids[2].to(DEVICE) + rel_2_4
    pos_4_from_3 = target_centroids[3].to(DEVICE) + rel_3_4 
    
    # Average the positions for compromise
    target_digit_4_position = (pos_4_from_2 + pos_4_from_3) / 2
    
    print(f"Target digit-4 position computed from spatial relationships")
    print(f"  From digit 2: distance = {torch.norm(rel_2_4):.4f}")
    print(f"  From digit 3: distance = {torch.norm(rel_3_4):.4f}")
    
    class SpatialConceptInjection(nn.Module):
        def __init__(self, target_sae, target_centroids, target_digit_4_position):
            super().__init__()
            self.target_sae = target_sae
            self.target_centroids = {k: v.to(DEVICE) for k, v in target_centroids.items()}
            self.target_digit_4_position = target_digit_4_position.to(DEVICE)
            
            # Learnable parameters for fine-tuning
            self.position_adjustment = nn.Parameter(torch.zeros_like(target_digit_4_position))
            self.injection_strength = nn.Parameter(torch.tensor(0.4, device=DEVICE))
            self.blend_weight = nn.Parameter(torch.tensor(0.85, device=DEVICE))
            
            # Digit-4 detector
            self.detector = nn.Sequential(
                nn.Linear(target_sae.concept_dim, 16),
                nn.ReLU(),
                nn.Linear(16, 1),
                nn.Sigmoid()
            ).to(DEVICE)
            
        def forward(self, target_features):
            # Encode to concept space
            target_concepts = self.target_sae.encode(target_features)
            
            # Detect digit-4 likelihood based on spatial proximity
            distances_to_anchors = []
            for anchor_digit in [2, 3]:
                if anchor_digit in self.target_centroids:
                    anchor_pos = self.target_centroids[anchor_digit]
                    distances = torch.norm(target_concepts - anchor_pos.unsqueeze(0), dim=1)
                    distances_to_anchors.append(distances)
            
            if distances_to_anchors:
                min_anchor_distance = torch.stack(distances_to_anchors).min(dim=0)[0]
                spatial_digit_4_prob = torch.sigmoid(-min_anchor_distance + 3.0)  # Closer to anchors = higher prob
            else:
                spatial_digit_4_prob = torch.zeros(target_concepts.shape[0], device=DEVICE)
            
            # Additional learned detection
            learned_digit_4_prob = self.detector(target_concepts).squeeze()
            
            # Combined probability
            digit_4_prob = 0.6 * spatial_digit_4_prob + 0.4 * learned_digit_4_prob
            
            # Inject digit-4 concept while preserving spatial relationships
            adjusted_position = self.target_digit_4_position + self.position_adjustment
            
            # Create enhanced concepts
            enhanced_concepts = target_concepts.clone()
            
            # Move concepts toward digit-4 position proportional to probability
            direction_to_4 = adjusted_position.unsqueeze(0) - target_concepts
            injection = self.injection_strength * digit_4_prob.unsqueeze(1) * direction_to_4
            
            enhanced_concepts += injection
            
            # Decode back to feature space
            enhanced_features = self.target_sae.decode(enhanced_concepts)
            
            # Blend with original features
            blend_weight = torch.sigmoid(self.blend_weight)
            blend_ratio = blend_weight + (1 - blend_weight) * (1 - digit_4_prob.unsqueeze(1))
            
            final_features = blend_ratio * target_features + (1 - blend_ratio) * enhanced_features
            
            return final_features, digit_4_prob
    
    # Create the injection layer
    injection_layer = SpatialConceptInjection(target_sae, target_centroids, target_digit_4_position)
    
    class SpatialTransferModel(nn.Module):
        def __init__(self, base_model, injection_layer):
            super().__init__()
            self.base_model = base_model
            self.injection_layer = injection_layer
            
        def forward(self, x):
            original_features = self.base_model.get_features(x)
            enhanced_features, digit_4_prob = self.injection_layer(original_features)
            
            # Get final layer
            if hasattr(self.base_model, 'fc4'):
                logits = self.base_model.fc4(enhanced_features)
            elif hasattr(self.base_model, 'fc3'):
                logits = self.base_model.fc3(enhanced_features)
            else:
                raise ValueError("Unknown architecture")
            
            return logits, digit_4_prob
        
        def forward_simple(self, x):
            logits, _ = self.forward(x)
            return logits
    
    spatial_model = SpatialTransferModel(target_model, injection_layer)
    
    return spatial_model

def optimize_spatial_model(spatial_model, digit_4_data, original_data, num_steps=50):
    """Optimize the spatial transfer model"""
    print("\n=== OPTIMIZING SPATIAL MODEL ===")
    
    optimizer = optim.Adam(spatial_model.injection_layer.parameters(), lr=0.01)
    
    digit_4_loader = DataLoader(digit_4_data, batch_size=24, shuffle=True)
    original_loader = DataLoader(original_data, batch_size=32, shuffle=True)
    
    spatial_model.train()
    
    for step in range(num_steps):
        total_loss = 0
        
        # Preservation loss
        for data, labels in original_loader:
            data, labels = data.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            
            enhanced_logits, _ = spatial_model(data)
            
            with torch.no_grad():
                original_logits = spatial_model.base_model(data)
            
            preservation_loss = nn.MSELoss()(enhanced_logits, original_logits)
            classification_loss = nn.CrossEntropyLoss()(enhanced_logits, labels)
            
            loss = 0.7 * preservation_loss + 0.3 * classification_loss
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            break
        
        # Transfer loss
        for data, _ in digit_4_loader:
            data = data.to(DEVICE)
            optimizer.zero_grad()
            
            enhanced_logits, digit_4_prob = spatial_model(data)
            
            targets = torch.full((data.shape[0],), 4, device=DEVICE)
            transfer_loss = nn.CrossEntropyLoss()(enhanced_logits, targets)
            detection_loss = -torch.mean(torch.log(digit_4_prob + 1e-8))
            
            loss = 0.2 * transfer_loss + 0.1 * detection_loss
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            break
        
        if step % 12 == 0:
            print(f"  Step {step}: Loss={total_loss:.4f}")
    
    return spatial_model

def evaluate_model(model, data_loader, name):
    """Evaluate model performance"""
    model.eval()
    correct = 0
    total = 0
    predictions = []
    
    if len(data_loader.dataset) == 0:
        return 0.0, []
    
    with torch.no_grad():
        for data, target in data_loader:
            data, target = data.to(DEVICE), target.to(DEVICE)
            
            if hasattr(model, 'forward_simple'):
                output = model.forward_simple(data)
            else:
                output = model(data)
            
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
            predictions.extend(predicted.cpu().numpy())
    
    accuracy = 100 * correct / total
    
    print(f"\n=== {name} ===")
    print(f"Accuracy: {accuracy:.2f}% ({correct}/{total})")
    
    # Prediction distribution
    pred_counts = {}
    for pred in predictions:
        pred_counts[pred] = pred_counts.get(pred, 0) + 1
    
    if len(pred_counts) <= 6:
        print("Predictions:", end=" ")
        for digit in sorted(pred_counts.keys()):
            count = pred_counts[digit]
            pct = 100 * count / total
            print(f"{digit}:{pct:.1f}%", end=" ")
        print()
    
    return accuracy, predictions

def test_spatial_relationship_transfer():
    """Test the spatial relationship transfer approach"""
    
    # Load data
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    
    full_train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
    full_test_dataset = datasets.MNIST('./data', train=False, download=False, transform=transform)
    
    # Create datasets
    class1_train = create_subset(full_train_dataset, [0, 1, 2, 3])  # Target model training
    class2_train = create_subset(full_train_dataset, [2, 3, 4, 5])  # Source model training
    
    shared_test = create_subset(full_test_dataset, [2, 3])
    digit_4_test = create_subset(full_test_dataset, [4])
    digit_5_test = create_subset(full_test_dataset, [5])
    original_test = create_subset(full_test_dataset, [0, 1, 2, 3])
    all_digits_test = create_subset(full_test_dataset, [0, 1, 2, 3, 4, 5])
    
    print(f"\n=== TRAINING MODELS ===")
    
    # Train models
    target_model = WideNN().to(DEVICE)
    target_model = train_model(target_model, class1_train, num_epochs=6)
    
    source_model = DeepNN().to(DEVICE)
    source_model = train_model(source_model, class2_train, num_epochs=6)
    
    # Analyze representation similarity
    digit_similarities, _, _, _ = analyze_representation_similarity(target_model, source_model, shared_test)
    
    print(f"\n=== TRAINING SAEs ===")
    
    # Train SAEs
    concept_dim = 24
    target_sae = train_concept_sae(target_model, shared_test, concept_dim)
    source_sae = train_concept_sae(source_model, shared_test, concept_dim)
    
    print(f"\n=== EXTRACTING CONCEPTS ===")
    
    # Extract concepts
    target_concepts = extract_digit_concepts(target_model, target_sae, all_digits_test, [0, 1, 2, 3])
    source_concepts = extract_digit_concepts(source_model, source_sae, all_digits_test, [2, 3, 4, 5])
    
    # Analyze spatial relationships in source model
    spatial_relationships, source_centroids = analyze_spatial_relationships(source_concepts)
    
    print(f"\n=== CREATING SPATIAL TRANSFER MODEL ===")
    
    # Create spatial transfer model
    spatial_model = create_spatial_transfer_model(target_model, target_sae, spatial_relationships, target_concepts)
    
    print(f"\n=== OPTIMIZATION ===")
    
    # Optimize
    optimized_model = optimize_spatial_model(spatial_model, digit_4_test, original_test, num_steps=40)
    
    print(f"\n" + "="*60)
    print("SPATIAL RELATIONSHIP TRANSFER RESULTS")
    print("="*60)
    
    # Evaluation
    digit_4_loader = DataLoader(digit_4_test, batch_size=128, shuffle=False)
    digit_5_loader = DataLoader(digit_5_test, batch_size=128, shuffle=False)
    original_loader = DataLoader(original_test, batch_size=128, shuffle=False)
    
    print(f"\nðŸ”µ BASELINE TARGET MODEL:")
    baseline_4, _ = evaluate_model(target_model, digit_4_loader, "Baseline - Digit 4")
    baseline_5, _ = evaluate_model(target_model, digit_5_loader, "Baseline - Digit 5")
    baseline_orig, _ = evaluate_model(target_model, original_loader, "Baseline - Original")
    
    print(f"\nðŸŸ¢ SPATIAL RELATIONSHIP MODEL:")
    spatial_4, _ = evaluate_model(optimized_model, digit_4_loader, "Spatial - Digit 4")
    spatial_5, _ = evaluate_model(optimized_model, digit_5_loader, "Spatial - Digit 5")
    spatial_orig, _ = evaluate_model(optimized_model, original_loader, "Spatial - Original")
    
    print(f"\n" + "="*60)
    print("SPATIAL RELATIONSHIP ASSESSMENT")
    print("="*60)
    
    print(f"\nðŸ“Š PERFORMANCE COMPARISON:")
    print(f"{'Metric':<20} {'Baseline':<12} {'Spatial':<12} {'Change':<10}")
    print(f"{'-'*55}")
    print(f"{'Digit 4 Transfer':<20} {baseline_4:<11.1f}% {spatial_4:<11.1f}% {spatial_4 - baseline_4:+.1f}%")
    print(f"{'Digit 5 Specificity':<20} {baseline_5:<11.1f}% {spatial_5:<11.1f}% {spatial_5 - baseline_5:+.1f}%")
    print(f"{'Original Preservation':<20} {baseline_orig:<11.1f}% {spatial_orig:<11.1f}% {spatial_orig - baseline_orig:+.1f}%")
    
    print(f"\nðŸ” REPRESENTATION ANALYSIS:")
    print(f"Digit 2 similarity between models: {digit_similarities[2]:.4f}")
    print(f"Digit 3 similarity between models: {digit_similarities[3]:.4f}")
    avg_similarity = (digit_similarities[2] + digit_similarities[3]) / 2
    print(f"Average 2,3 similarity: {avg_similarity:.4f}")
    
    print(f"\nðŸŽ¯ SPATIAL RELATIONSHIP PRESERVATION:")
    if 'target_relationships' in spatial_relationships:
        rel_info = spatial_relationships['target_relationships']
        print(f"2â†’4 relationship distance: {torch.norm(rel_info['2â†’4']):.4f}")
        print(f"3â†’4 relationship distance: {torch.norm(rel_info['3â†’4']):.4f}")
        print(f"Angular relationship: {rel_info['angle']:.1f}Â°")
    
    # Success metrics
    transfer_success = spatial_4 > baseline_4 + 10
    preservation_success = spatial_orig > baseline_orig - 5
    specificity_success = spatial_5 <= baseline_5 + 5
    
    print(f"\nðŸŽ¯ SUCCESS METRICS:")
    print(f"Transfer Success: {'âœ…' if transfer_success else 'âŒ'} (+{spatial_4 - baseline_4:.1f}%)")
    print(f"Preservation: {'âœ…' if preservation_success else 'âŒ'} ({spatial_orig - baseline_orig:+.1f}%)")
    print(f"Specificity: {'âœ…' if specificity_success else 'âŒ'} (+{spatial_5 - baseline_5:.1f}%)")
    
    overall_success = transfer_success and preservation_success and specificity_success
    
    if overall_success:
        print(f"\nðŸš€ SPATIAL RELATIONSHIP SUCCESS!")
        print(f"Successfully preserved spatial relationships in transfer!")
    elif transfer_success:
        print(f"\nðŸ”¬ SIGNIFICANT SPATIAL TRANSFER PROGRESS!")
        print(f"Transfer achieved: +{spatial_4 - baseline_4:.1f}% on digit 4")
    else:
        print(f"\nðŸ§  Spatial relationship framework established")
        print(f"Representation similarity: {avg_similarity:.4f}")
    
    return {
        'digit_similarities': digit_similarities,
        'transfer_improvement': spatial_4 - baseline_4,
        'preservation_change': spatial_orig - baseline_orig,
        'avg_similarity': avg_similarity,
        'success': overall_success
    }

if __name__ == "__main__":
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    print("Testing spatial relationship transfer\n")
    
    results = test_spatial_relationship_transfer()
    
    if results:
        print(f"\nðŸ“‹ SPATIAL RELATIONSHIP SUMMARY:")
        print(f"Representation similarity 2,3: {results['avg_similarity']:.4f}")
        print(f"Digit-4 improvement: +{results['transfer_improvement']:.1f}%")
        print(f"Preservation change: {results['preservation_change']:+.1f}%")
        
        if results['success']:
            print(f"\nâœ¨ SPATIAL RELATIONSHIP BREAKTHROUGH!")
            print(f"Successfully maintained geometric structure in concept space!")
        else:
            print(f"\nðŸ”¬ Spatial relationship framework validated")
    
    print(f"\nðŸ“‹ SPATIAL APPROACH COMPONENTS:")
    print(f"âœ“ Representation similarity analysis between models")
    print(f"âœ“ Spatial relationship extraction (2â†’4, 3â†’4 vectors)")
    print(f"âœ“ Geometric structure preservation in target space")
    print(f"âœ“ Position-based digit-4 concept injection")
    print(f"âœ“ Angular relationship maintenance")